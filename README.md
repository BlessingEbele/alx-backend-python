# ğŸŒ€ ALX Backend Python â€“ Generators & SQL Streaming

Welcome to the **Python Generators and SQL Integration Module** of the ALX Backend curriculum.  
This project demonstrates how to work with **Python generators**, large datasets, and **real-time SQL streaming** in a memory-efficient way.

---

## ğŸ“š Project Overview

This module focuses on using Python's `yield` and generator functions to process data **efficiently** and **incrementally** â€” an essential skill for backend developers working with **large datasets**, **streaming applications**, and **live dashboards**.

---

## ğŸ“ Directory Structure

alx-backend-python/
â”œâ”€â”€ python-generators-0x00/
â”‚ â”œâ”€â”€ 0-main.py
â”‚ â”œâ”€â”€ seed.py
â”‚ â”œâ”€â”€ user_data.csv
â”‚ â”œâ”€â”€ README.md
â”‚ â””â”€â”€ ...
â”œâ”€â”€ README.md <-- (this file)


---

## ğŸ¯ Learning Objectives

By the end of this project, you will be able to:

- âœ… Create Python **generator functions** using `yield`
- âœ… Stream data from a **SQL database row-by-row**
- âœ… Handle **large datasets** without overloading memory
- âœ… Simulate **real-world streaming behavior**
- âœ… Use **SQL queries dynamically** inside Python
- âœ… Integrate **Python + MySQL/SQLite** for high-performance data access

---

## ğŸ”§ Technologies & Tools

- **Python 3.x**
- **MySQL** (via `mysql-connector-python`)
- **CSV & file handling**
- **UUIDs, Indexed Primary Keys**
- **SQL Performance Profiling**

---

## ğŸš€ Getting Started

### Setup

1. Clone the repository:
```bash
git clone https://github.com/your-username/alx-backend-python.git
cd alx-backend-python/python-generators-0x00
Install dependencies:


pip install mysql-connector-python
Update seed.py with your actual MySQL password and run:


chmod +x 0-main.py
./0-main.py
ğŸ§ª What Youâ€™ll Build
âœ… A full pipeline that:

Seeds a MySQL database (ALX_prodev)

Creates a user_data table with UUIDs

Populates it from a CSV file

Streams rows one-by-one using a generator function (in the next task)

`````
# ğŸŒ€ Python Generators with SQL Integration

This directory contains Python scripts that demonstrate **advanced usage of generator functions** for efficient, memory-safe data processing using **SQL databases**.

It is part of the **ALX Backend Python** project series.

---

## ğŸ“š Learning Objectives

By completing this module, you will:

- âœ… Use Python generator functions with `yield` to iterate through large datasets
- âœ… Stream SQL rows efficiently, row-by-row or in batches
- âœ… Handle large data without memory overload
- âœ… Process batches with filtering logic
- âœ… Seed SQL databases from CSV
- âœ… Combine Python with MySQL for real-world backend use cases

---

## ğŸ“ Files in this Directory

| File Name              | Description |
|------------------------|-------------|
| `0-main.py`            | Script to test DB creation and seeding |
| `seed.py`              | Creates MySQL DB (`ALX_prodev`), `user_data` table, and seeds from CSV |
| `user_data.csv`        | Sample dataset with user information |
| `1-main.py`            | Test script to print rows using generator from `0-stream_users.py` |
| `0-stream_users.py`    | Streams rows one at a time using generator |
| `2-main.py`            | Tests batch streaming & filtering from `1-batch_processing.py` |
| `1-batch_processing.py`| Streams user data in batches & filters for users older than 25 |
| `README.md`            | This file |

---

## âœ… Task 0: Seed MySQL Database

**Goal:** Create `ALX_prodev` DB and populate `user_data` table using `user_data.csv`.

**Script:** `seed.py`

### Functions:
```python
def connect_db()
def create_database(connection)
def connect_to_prodev()
def create_table(connection)
def insert_data(connection, csv_file)
âœ… Task 1: Stream SQL Rows One-by-One
Goal: Use a generator to lazily stream individual user rows from the user_data table.

Script: 0-stream_users.py
Tested with: 1-main.py

Function:
python
def stream_users()
âœ… Task 2: Batch Processing with Generators
Goal: Use generator to process user records in batches, then filter and print only users over the age of 25.

Script: 1-batch_processing.py
Tested with: 2-main.py

Functions:
python
def stream_users_in_batches(batch_size)
def batch_processing(batch_size)

Sample Output:
bash
{'user_id': '00234e...', 'name': 'Dan Altenwerth Jr.', 'age': 67}
{'user_id': '006bfede...', 'name': 'Glenda Wisozk', 'age': 119}
...
âœ… Memory Efficient
âœ… Processes data in chunks
âœ… Only 3 loops used


`````

âœï¸ Author
Blessing Ebele Anochili
Backend Developer | Python Enthusiast | ALX SE Program
ğŸ”— GitHub: https://github.com/BlessingEbele/
ğŸŒ Lagos, Nigeria

ğŸ”– License
This project is part of the ALX Software Engineering program and follows the ALX project submission guidelines.
